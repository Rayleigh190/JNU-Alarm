import requests
from bs4 import BeautifulSoup
import pprint
from datetime import datetime

from .models import User, Notification
from .models import Department, Architecture, MaterialsEngineering, MechanicalEngineering, SoftwareEngineering
from .models import College, Engineering

def send_message(title, body, users, link):
  for user in users:
    Notification.objects.create(user=user, category=title, title=body, link=link)
  print(f"pushed to {users}")
  return

def crawling_job():
  architecture_crawling()
  materials_engineering_crawling()
  mechanical_engineering_crawling()
  software_engineering_crawling()
  engineering_crawling()

def general_crawling(base_url, url, department_model):
  response = requests.get(url)
  soup = BeautifulSoup(response.text, 'html.parser')
  posts = []
  last_post = department_model.objects.last()
  for tr in soup.findAll('tr', attrs={'class':''}):
    try:
      if tr.find('td') is None:
        continue
      num = int(tr.find('td', attrs={'class':'td-num'}).text)
      if num <= last_post.num:
        break
      else:
        td = tr.find('td', attrs={'class':'td-subject'})
        title = td.find('strong').text
        href = td.find('a')['href']
        postUrl = base_url + href
        post_data = {
          'num': num,
          'title': title,
          'url': postUrl
        }
        posts.append(post_data)
    except Exception as e:
      print("í¬ë¡¤ë§ì¤‘ ì˜ˆì™¸ ë°œìƒ", e)
      pass
  return posts

## í•™ê³¼ í´ë¡¤ë§
# ê±´ì¶•í•™ë¶€
def architecture_crawling():
  today = str(datetime.now())
  base_url = "https://archi.jnu.ac.kr"
  url = 'https://archi.jnu.ac.kr/archi/8023/subview.do'
  posts = general_crawling(base_url=base_url, url=url, department_model=Architecture)
  
  if len(posts) > 0:
    for post in reversed(posts):
      Architecture.objects.create(num=post['num'], title=post['title'])
      isTrue_departments = Department.objects.filter(architecture=True)
      isTrue_users = User.objects.filter(setting__department__in=isTrue_departments)
      print(f"{today} : ğŸ  ê±´ì¶•í•™ë¶€ ì•Œë¦¼ ë°œì†¡")
      pprint.pprint(post)
      send_message("ê±´ì¶•í•™ë¶€", post['title'], isTrue_users, post['url'])
  else:
    print(f"{today} : ğŸ  ê±´ì¶•í•™ë¶€ ìƒˆë¡œìš´ ê³µì§€ ì—†ìŒ")

# ê³ ë¶„ììœµí•©ì†Œì¬ê³µí•™ë¶€
def materials_engineering_crawling():
  today = str(datetime.now())
  base_url = "https://pf.jnu.ac.kr"
  url = 'https://pf.jnu.ac.kr/pf/7821/subview.do'
  posts = general_crawling(base_url=base_url, url=url, department_model=MaterialsEngineering)
  
  if len(posts) > 0:
    for post in reversed(posts):
      MaterialsEngineering.objects.create(num=post['num'], title=post['title'])
      isTrue_departments = Department.objects.filter(materials_engineering=True)
      isTrue_users = User.objects.filter(setting__department__in=isTrue_departments)
      print(f"{today} : ğŸ’ ê³ ë¶„ììœµí•©ì†Œì¬ê³µí•™ë¶€ ì•Œë¦¼ ë°œì†¡")
      pprint.pprint(post)
      send_message("ê³ ë¶„ììœµí•©ì†Œì¬ê³µí•™ë¶€", post['title'], isTrue_users, post['url'])
  else:
    print(f"{today} : ğŸ’ ê³ ë¶„ììœµí•©ì†Œì¬ê³µí•™ë¶€ ìƒˆë¡œìš´ ê³µì§€ ì—†ìŒ")

# ê¸°ê³„ê³µí•™ë¶€
def mechanical_engineering_crawling():
  today = str(datetime.now())
  base_url = "https://mech.jnu.ac.kr"
  url = 'https://mech.jnu.ac.kr/mech/8218/subview.do'
  posts = general_crawling(base_url=base_url, url=url, department_model=MechanicalEngineering)
  
  if len(posts) > 0:
    for post in reversed(posts):
      MechanicalEngineering.objects.create(num=post['num'], title=post['title'])
      isTrue_departments = Department.objects.filter(mechanical_engineering=True)
      isTrue_users = User.objects.filter(setting__department__in=isTrue_departments)
      print(f"{today} : âš™ï¸ ê¸°ê³„ê³µí•™ë¶€ ì•Œë¦¼ ë°œì†¡")
      pprint.pprint(post)
      send_message("ê¸°ê³„ê³µí•™ë¶€", post['title'], isTrue_users, post['url'])
  else:
    print(f"{today} : âš™ï¸ ê¸°ê³„ê³µí•™ë¶€ ìƒˆë¡œìš´ ê³µì§€ ì—†ìŒ")

# ì†Œí”„íŠ¸ì›¨ì–´ê³µí•™ê³¼
def software_engineering_crawling():
  today = str(datetime.now())
  base_url = "https://sw.jnu.ac.kr"
  url = 'https://sw.jnu.ac.kr/sw/8250/subview.do'
  posts = general_crawling(base_url=base_url, url=url, department_model=SoftwareEngineering)
  
  if len(posts) > 0:
    for post in reversed(posts):
      SoftwareEngineering.objects.create(num=post['num'], title=post['title'])
      # ì†Œí”„íŠ¸ì›¨ì–´ê³µí•™ê³¼ë¥¼ êµ¬ë…í•œ Userì—ê²Œ ì•Œë¦¼ ë°œì†¡
      isTrue_departments = Department.objects.filter(software_engineering=True)
      isTrue_users = User.objects.filter(setting__department__in=isTrue_departments)
      print(f"{today} : ğŸ’» ì†Œí”„íŠ¸ì›¨ì–´ê³µí•™ê³¼ ì•Œë¦¼ ë°œì†¡")
      pprint.pprint(post)
      send_message("ì†Œí”„íŠ¸ì›¨ì–´ê³µí•™ê³¼", post['title'], isTrue_users, post['url'])
  else:
    print(f"{today} : ğŸ’» ì†Œí”„íŠ¸ì›¨ì–´ê³µí•™ê³¼ ìƒˆë¡œìš´ ê³µì§€ ì—†ìŒ")

# ê³µê³¼ëŒ€í•™
def engineering_crawling():
  today = str(datetime.now())
  base_url = "https://eng.jnu.ac.kr"
  url = 'https://eng.jnu.ac.kr/eng/7343/subview.do'
  posts = general_crawling(base_url=base_url, url=url, department_model=Engineering)
  
  if len(posts) > 0:
    for post in reversed(posts):
      Engineering.objects.create(num=post['num'], title=post['title'])
      # ê³µê³¼ëŒ€í•™ì„ êµ¬ë…í•œ Userì—ê²Œ ì•Œë¦¼ ë°œì†¡
      isTrue_college =College.objects.filter(engineering=True)
      isTrue_users = User.objects.filter(setting__college__in=isTrue_college)
      print(f"{today} : ğŸ› ï¸ ê³µê³¼ëŒ€í•™ ì•Œë¦¼ ë°œì†¡")
      pprint.pprint(post)
      send_message("ê³µê³¼ëŒ€í•™", post['title'], isTrue_users, post['url'])
  else:
    print(f"{today} : ğŸ› ï¸ ê³µê³¼ëŒ€í•™ ìƒˆë¡œìš´ ê³µì§€ ì—†ìŒ")